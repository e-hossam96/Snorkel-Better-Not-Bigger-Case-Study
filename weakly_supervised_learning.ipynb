{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff6fb58",
   "metadata": {},
   "source": [
    "# Weakly Learning on IMDB Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1856958",
   "metadata": {},
   "source": [
    "Learning using BERT base uncased over the weak labels of the IMDB dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d23aed5",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5208102d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_style('white')\n",
    "sns.set_context('notebook')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176ccf65",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31ab25de",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json('./train.json')\n",
    "temp_df = pd.read_json('./valid.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acb96e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = temp_df.iloc[:20000, :].reset_index(drop=True)\n",
    "test_df = temp_df.iloc[20000:, :].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68b6e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "train_ds = Dataset.from_pandas(train_df[['text', 'weak_labels']], split='train')\n",
    "valid_ds = Dataset.from_pandas(valid_df[['text', 'weak_labels']], split='valid')\n",
    "test_ds = Dataset.from_pandas(test_df[['text', 'label']], split='test')\n",
    "\n",
    "ds = DatasetDict({'train': train_ds, 'valid': valid_ds, 'test': test_ds})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26c604f8-5e6c-4abc-a34f-15b5ec428b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['train'] = ds['train'].remove_columns(['__index_level_0__'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1026e602-7fd7-4214-b8a9-9444e9297f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['train'] = ds['train'].rename_column('weak_labels', 'label')\n",
    "ds['valid'] = ds['valid'].rename_column('weak_labels', 'label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54850e76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25624\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 6368\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5593cb1a",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60f8d4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_ckpt = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14d0c856",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_ds(field):\n",
    "    '''Tokenize examples from dataset.'''\n",
    "    return tokenizer(field['text'], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3541c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af1ec669e5764062b09249c81caf5ba1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19949ebd90ca4da091904d4b8666b37b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa45d0c06a874d9a85616f33d84c3d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_encoded = ds.map(tokenize_ds, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31f93031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 25624\n",
       "    })\n",
       "    valid: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 6368\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb0a042",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "df55bb1f-a2d5-4784-ba2c-ec931d62df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorWithPadding\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c65b6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_scores(preds):\n",
    "    '''Compute scores of transformers predictions.'''\n",
    "    logits, labels = preds\n",
    "    pred = np.argmax(logits, axis=-1)\n",
    "    acc = accuracy_score(labels, pred)\n",
    "    f1 = f1_score(labels, pred)\n",
    "    return {'Accuracy': acc, 'F1 Score': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25170292",
   "metadata": {},
   "outputs": [],
   "source": [
    "id2label = {0: 'negative', 1: 'positive'}\n",
    "label2id = {'negative': 0, 'positive': 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1004bbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, TrainingArguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c260dcde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(model_ckpt, num_labels=2, \n",
    "                          id2label=id2label, label2id=label2id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "207190a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=\"./bert-base-uncased-imdb\", \n",
    "                                  learning_rate=2e-5, \n",
    "                                  per_device_train_batch_size=16, \n",
    "                                  per_device_eval_batch_size=16, \n",
    "                                  num_train_epochs=2, \n",
    "                                  weight_decay=0.01, \n",
    "                                  evaluation_strategy=\"epoch\", \n",
    "                                  save_strategy=\"epoch\", \n",
    "                                  load_best_model_at_end=True, \n",
    "                                  logging_steps=500, \n",
    "                                  log_level=\"error\", \n",
    "                                  push_to_hub=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3735f969",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model=model, \n",
    "                  args=training_args, \n",
    "                  train_dataset=ds_encoded['train'], \n",
    "                  eval_dataset=ds_encoded['valid'], \n",
    "                  tokenizer=tokenizer, \n",
    "                  data_collator=data_collator, \n",
    "                  compute_metrics=compute_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dfb62a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33me_hossam96\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.13.4"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/notebooks/snorkel-better-not-bigger/wandb/run-20230420_054042-2qwnrnxd</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/e_hossam96/huggingface/runs/2qwnrnxd\" target=\"_blank\">./bert-base-uncased-imdb</a></strong> to <a href=\"https://wandb.ai/e_hossam96/huggingface\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3204' max='3204' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3204/3204 48:17, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.444600</td>\n",
       "      <td>0.430442</td>\n",
       "      <td>0.790650</td>\n",
       "      <td>0.855606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.346100</td>\n",
       "      <td>0.448653</td>\n",
       "      <td>0.797100</td>\n",
       "      <td>0.864571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3204, training_loss=0.40822319859422546, metrics={'train_runtime': 2901.4306, 'train_samples_per_second': 17.663, 'train_steps_per_second': 1.104, 'total_flos': 1.333559472985056e+16, 'train_loss': 0.40822319859422546, 'epoch': 2.0})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d830e8f1-0e19-404d-a5e4-8f258b9e2472",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'test_loss': 0.49959537386894226,\n",
       " 'test_Accuracy': 0.7407349246231156,\n",
       " 'test_F1 Score': 0.7915667213735639,\n",
       " 'test_runtime': 98.4085,\n",
       " 'test_samples_per_second': 64.71,\n",
       " 'test_steps_per_second': 4.044}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing the model\n",
    "\n",
    "test_outs = trainer.predict(ds_encoded['test'])\n",
    "\n",
    "test_outs.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a2657e8-12a3-48f6-b943-339810c618db",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(test_outs[0], axis=-1)\n",
    "labels = test_outs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44a26546-5284-4b29-b13e-5bfb59c24632",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.50      0.66      3146\n",
      "           1       0.67      0.97      0.79      3222\n",
      "\n",
      "    accuracy                           0.74      6368\n",
      "   macro avg       0.81      0.74      0.72      6368\n",
      "weighted avg       0.81      0.74      0.73      6368\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(labels, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
